{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2GPoeVHUVTq"
   },
   "source": [
    "# Практическое задание 1\n",
    "\n",
    "\n",
    "\n",
    "## Замечания\n",
    "* Задание необходимо сдать боту до 15.11.2021\n",
    "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
    "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
    "* Ничего, крому Numpy, нельзя использовать для реализации \n",
    "* **Keras** используется только для тестирования Вашей реализации\n",
    "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
    "* Возможно использование дополнительных (приватных) тестов\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hT1dNA7Gb35a"
   },
   "outputs": [],
   "source": [
    "# Вам понадобится для реализации\n",
    "import keras.layers as layers\n",
    "import numpy as np\n",
    "\n",
    "# Нужно для тестирования\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G7sQn2ZXh9Y"
   },
   "source": [
    "* Вспомогательные функции для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_vXhfmihINmY"
   },
   "outputs": [],
   "source": [
    "def compare_tensors(x, y, tol=0.001, test_name=\"Test\"):\n",
    "    assert x.shape == y.shape, test_name + \" different shapes\"\n",
    "    diff = np.sum((y - x) ** 2)\n",
    "    assert diff < tol, test_name + \" Failed!\"\n",
    "    print(test_name + \" Passed!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pq_lVMUle_ii"
   },
   "outputs": [],
   "source": [
    "def compare_tensors_array(x, y, tol=0.001, test_name=\"Test\"):\n",
    "    assert len(x) == len(y), test_name + \" different lengths\"\n",
    "    for i in range(len(x)):\n",
    "        t = test_name + \" subtest \" + str(i)\n",
    "        compare_tensors(x[i], y[i], tol=tol, test_name=t)\n",
    "    print(test_name + \" Passed!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4iNYGlDyNAF"
   },
   "source": [
    "* Шаблон класса любой операции (слоя), которую Вам необходимо будет реализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "05lYhmjMSm0s"
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self):\n",
    "        self.name = \"Layer\"\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендуется запускать на GPU. В таком случае keras не ругается на channels_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caE-Xn1ZY79p"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9yuQiPjyOBZ"
   },
   "source": [
    "* (1 балл) Реализация \"спрямляющего\" слоя Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zJIqDFDC-8Gh"
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    def __init__(self):\n",
    "        self.name = \"Flatten\"\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "        # Преобразуем в двухмерный тензор: при этом по первой размерности НЕ преобразуем\n",
    "        # Выкладываем данные: сначала по последней размерности, затем по предпоследней и т.д.\n",
    "        # Нужно заполнить Numpy-тензор out\n",
    "        data = np.swapaxes(input_data, 1, 3)\n",
    "        out = np.reshape(np.swapaxes(data, 1, 2), (data.shape[0], -1))\n",
    "        return out\n",
    "\n",
    "    # решейп начинал расплющивать с последних размерностей, а флеттен от керас, наоборот, с внешних размерностей, поэтому пришлось\n",
    "    # добавить свап осей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAD92fJkYcNI"
   },
   "source": [
    "* Функция предварительного тестирования слоя **Flatten**\n",
    "* Функции с названием \"**test_**\" не менять\n",
    "* Вы можете самостоятельно поиграться с параметрами типа B/C/H/W etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eZsoCXd1HioL"
   },
   "outputs": [],
   "source": [
    "def test_FlattenLayer():\n",
    "    B = 1\n",
    "    C = 1\n",
    "    H = 3\n",
    "    W = 3\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.Flatten(data_format=\"channels_first\")\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = FlattenLayer().forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Flatten 1\")\n",
    "    B = 1\n",
    "    C = 2\n",
    "    H = 3\n",
    "    W = 3\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.Flatten(data_format=\"channels_first\")\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = FlattenLayer().forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Flatten 2\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_FlattenLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C = np.random.randint(low=1, high=30)\n",
    "        H = np.random.randint(low=1, high=30)\n",
    "        W = np.random.randint(low=1, high=30)\n",
    "        print(f\"Test {i+1}, B:{B}, C:{C}, H:{H}, W:{W}\")\n",
    "        x = np.random.randn(B, C, H, W)\n",
    "        y = layers.Flatten(data_format=\"channels_first\")\n",
    "        y_keras = y(x).numpy()\n",
    "        y_out = FlattenLayer().forward(x)\n",
    "        compare_tensors(y_keras, y_out, tol=0.001, test_name=f\"Test Flatten {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pST9EihGKTEh",
    "outputId": "fa328294-95bb-41ce-a449-ff147d0455fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Flatten 1 Passed!\n",
      "Test Flatten 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_FlattenLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNUdshs2lmWF",
    "outputId": "b44ee260-d38d-4e6c-d422-1b8dfe99ae91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:27, C:9, H:11, W:7\n",
      "Test Flatten 1 Passed!\n",
      "Test 2, B:28, C:24, H:3, W:15\n",
      "Test Flatten 2 Passed!\n",
      "Test 3, B:27, C:29, H:28, W:22\n",
      "Test Flatten 3 Passed!\n",
      "Test 4, B:3, C:12, H:14, W:5\n",
      "Test Flatten 4 Passed!\n",
      "Test 5, B:25, C:1, H:1, W:13\n",
      "Test Flatten 5 Passed!\n",
      "Test 6, B:5, C:1, H:8, W:1\n",
      "Test Flatten 6 Passed!\n",
      "Test 7, B:24, C:24, H:20, W:20\n",
      "Test Flatten 7 Passed!\n",
      "Test 8, B:13, C:17, H:1, W:20\n",
      "Test Flatten 8 Passed!\n",
      "Test 9, B:15, C:2, H:26, W:7\n",
      "Test Flatten 9 Passed!\n",
      "Test 10, B:20, C:25, H:15, W:18\n",
      "Test Flatten 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_FlattenLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOngWlbqyQJ9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NfaNFKZGOk"
   },
   "source": [
    "* (1 балл) Реализация слоя субдискретизации **Global Average Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1d3U8gE1-8J1"
   },
   "outputs": [],
   "source": [
    "class GAP2DLayer(Layer):\n",
    "    def __init__(self):\n",
    "        self.name = \"GAP2D\"\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "        # Сворачиваем по двум последним размерностям (то есть на выходе - минус две размерности)\n",
    "        # Нужно заполнить Numpy-тензор out\n",
    "        return input_data.mean(axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u9KLCdrTLT-j"
   },
   "outputs": [],
   "source": [
    "def test_GAP2DLayer():\n",
    "    B = 1\n",
    "    C = 1\n",
    "    H = 3\n",
    "    W = 3\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.GlobalAveragePooling2D(data_format=\"channels_first\")\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = GAP2DLayer().forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test GAP2D 1\")\n",
    "    B = 1\n",
    "    C = 2\n",
    "    H = 3\n",
    "    W = 3\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.GlobalAveragePooling2D(data_format=\"channels_first\")\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = GAP2DLayer().forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test GAP2D 2\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_GAP2DLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C = np.random.randint(low=1, high=30)\n",
    "        H = np.random.randint(low=1, high=30)\n",
    "        W = np.random.randint(low=1, high=30)\n",
    "        print(f\"Test {i+1}, B:{B}, C:{C}, H:{H}, W:{W}\")\n",
    "        x = np.random.randn(B, C, H, W)\n",
    "        y = layers.GlobalAveragePooling2D(data_format=\"channels_first\")\n",
    "        y_keras = y(x).numpy()\n",
    "        y_out = GAP2DLayer().forward(x)\n",
    "        compare_tensors(y_keras, y_out, tol=0.001, test_name=f\"Test GAP2D {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbuDxhloPLKs",
    "outputId": "d23438e4-b061-4194-f8ee-fc7bd7dedcca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test GAP2D 1 Passed!\n",
      "Test GAP2D 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_GAP2DLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUBZjLgAlmWG",
    "outputId": "090fc426-339e-4f09-89be-aaa4f0944f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:25, C:15, H:3, W:16\n",
      "Test GAP2D 1 Passed!\n",
      "Test 2, B:16, C:18, H:12, W:23\n",
      "Test GAP2D 2 Passed!\n",
      "Test 3, B:4, C:15, H:2, W:19\n",
      "Test GAP2D 3 Passed!\n",
      "Test 4, B:25, C:1, H:20, W:20\n",
      "Test GAP2D 4 Passed!\n",
      "Test 5, B:3, C:13, H:22, W:16\n",
      "Test GAP2D 5 Passed!\n",
      "Test 6, B:15, C:14, H:11, W:5\n",
      "Test GAP2D 6 Passed!\n",
      "Test 7, B:24, C:27, H:27, W:28\n",
      "Test GAP2D 7 Passed!\n",
      "Test 8, B:2, C:15, H:17, W:17\n",
      "Test GAP2D 8 Passed!\n",
      "Test 9, B:16, C:28, H:15, W:24\n",
      "Test GAP2D 9 Passed!\n",
      "Test 10, B:1, C:17, H:27, W:6\n",
      "Test GAP2D 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_GAP2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbse3gb2ySI_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2CCmuiZZTXp"
   },
   "source": [
    "* (2 балла) Реализация слоя субдискретизации **MaxPooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fFSW6Xpp-8NS"
   },
   "outputs": [],
   "source": [
    "class MaxPool2DLayer(Layer):\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "        self.name = \"MaxPool2D\"\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        out_h = int((input_data.shape[2] - (self.pool_size - 1) - 1) / self.stride + 1)\n",
    "        out_w = int((input_data.shape[3] - (self.pool_size - 1) - 1) / self.stride + 1)\n",
    "        out = np.empty((input_data.shape[0], input_data.shape[1], out_h, out_w))\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                out[:, :, i, j] = np.max(\n",
    "                    input_data[\n",
    "                        :,\n",
    "                        :,\n",
    "                        i * self.stride : i * self.stride + self.pool_size,\n",
    "                        j * self.stride : j * self.stride + self.pool_size,\n",
    "                    ],\n",
    "                    axis=(2, 3),\n",
    "                )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kvCIn_aXUPkD"
   },
   "outputs": [],
   "source": [
    "def test_MaxPool2DLayer():\n",
    "    B = 1\n",
    "    C = 1\n",
    "    H = 4\n",
    "    W = 4\n",
    "    pool_size = 2\n",
    "    stride = 2\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.MaxPooling2D(\n",
    "        pool_size=pool_size,\n",
    "        strides=stride,\n",
    "        padding=\"valid\",\n",
    "        data_format=\"channels_first\",\n",
    "    )\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test MaxPool2D 1\")\n",
    "    B = 2\n",
    "    C = 2\n",
    "    H = 3\n",
    "    W = 3\n",
    "    pool_size = 2\n",
    "    stride = 1\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.MaxPooling2D(\n",
    "        pool_size=pool_size,\n",
    "        strides=stride,\n",
    "        padding=\"valid\",\n",
    "        data_format=\"channels_first\",\n",
    "    )\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test MaxPool2D 2\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_MaxPool2DLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C = np.random.randint(low=1, high=30)\n",
    "        H = np.random.randint(low=2, high=30)\n",
    "        W = np.random.randint(low=2, high=30)\n",
    "        pool_size = np.random.randint(\n",
    "            low=1, high=min(H, W)\n",
    "        )  # т.к. нет паддинга, и не будем сворачивать больше самой картинки\n",
    "        stride = np.random.randint(low=1, high=min(H, W))\n",
    "        print(\n",
    "            f\"Test {i+1}, B:{B}, C:{C}, H:{H}, W:{W}, pool_size:{pool_size}, stride:{stride}\"\n",
    "        )\n",
    "        x = np.random.randn(B, C, H, W)\n",
    "        y = layers.MaxPooling2D(\n",
    "            pool_size=pool_size,\n",
    "            strides=stride,\n",
    "            padding=\"valid\",\n",
    "            data_format=\"channels_first\",\n",
    "        )\n",
    "        y_keras = y(x).numpy()\n",
    "        y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "        compare_tensors(y_keras, y_out, tol=0.001, test_name=f\"Test MaxPool2D {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GHRtvEIpVsYe",
    "outputId": "004dbae0-60b8-4c9e-8ecd-28ce3e95c5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MaxPool2D 1 Passed!\n",
      "Test MaxPool2D 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_MaxPool2DLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Erx6AQPPlmWH",
    "outputId": "56d91b72-d9f5-44ef-e02e-f40a79c739bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:17, C:3, H:20, W:8, pool_size:6, stride:2\n",
      "Test MaxPool2D 1 Passed!\n",
      "Test 2, B:9, C:11, H:22, W:6, pool_size:2, stride:4\n",
      "Test MaxPool2D 2 Passed!\n",
      "Test 3, B:5, C:25, H:6, W:20, pool_size:2, stride:5\n",
      "Test MaxPool2D 3 Passed!\n",
      "Test 4, B:2, C:1, H:24, W:14, pool_size:13, stride:7\n",
      "Test MaxPool2D 4 Passed!\n",
      "Test 5, B:29, C:28, H:14, W:11, pool_size:5, stride:7\n",
      "Test MaxPool2D 5 Passed!\n",
      "Test 6, B:3, C:23, H:25, W:8, pool_size:4, stride:5\n",
      "Test MaxPool2D 6 Passed!\n",
      "Test 7, B:2, C:14, H:17, W:23, pool_size:8, stride:11\n",
      "Test MaxPool2D 7 Passed!\n",
      "Test 8, B:9, C:11, H:26, W:25, pool_size:1, stride:17\n",
      "Test MaxPool2D 8 Passed!\n",
      "Test 9, B:5, C:13, H:6, W:14, pool_size:1, stride:2\n",
      "Test MaxPool2D 9 Passed!\n",
      "Test 10, B:14, C:14, H:10, W:19, pool_size:8, stride:3\n",
      "Test MaxPool2D 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_MaxPool2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLtOD86byTQ-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zruUuHDeZf-4"
   },
   "source": [
    "* (3 балла) Реализация слоя **активации** (поддерживаются **relu**, **sigmoid**, **softmax**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yFytq6FOByQ9"
   },
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        # Активация (поддерживаем 'relu', 'sigmoid', 'softmax')\n",
    "        self.name = \"Activation\"\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # На входе:\n",
    "        # четырехмерный тензор вида [batch, input_channels, height, width] для 'relu', 'sigmoid'\n",
    "        # или двухмерный тензор вида [batch, logits]\n",
    "        # SoftMax применяется по последней размерности\n",
    "        # Нужно заполнить Numpy-тензор out\n",
    "        out = np.empty_like(input_data)\n",
    "        if self.activation == \"relu\":\n",
    "            input_data[input_data < 0] = 0\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            input_data = 1 / (1 + np.exp(-input_data))\n",
    "        elif self.activation == \"softmax\":\n",
    "            for i in range(len(input_data)):\n",
    "                denominator = sum(np.exp(input_data[i]))\n",
    "                input_data[i] = np.exp(input_data[i]) / denominator\n",
    "\n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-RnOBuLTWcIf"
   },
   "outputs": [],
   "source": [
    "def test_ActivationLayer():\n",
    "    B = 1\n",
    "    C = 1\n",
    "    H = 4\n",
    "    W = 4\n",
    "    activation = \"relu\"\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.Activation(activation)\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = ActivationLayer(activation=activation).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Activation 1\")\n",
    "    B = 2\n",
    "    C = 2\n",
    "    H = 3\n",
    "    W = 3\n",
    "    activation = \"sigmoid\"\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.Activation(activation)\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = ActivationLayer(activation=activation).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Activation 2\")\n",
    "    B = 3\n",
    "    C = 10\n",
    "    activation = \"softmax\"\n",
    "    x = np.random.randn(B, C)\n",
    "    y = layers.Activation(activation)\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = ActivationLayer(activation=activation).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Activation 3\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_ActivationLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        activations = [\"relu\", \"sigmoid\", \"softmax\"]\n",
    "        activation = activations[np.random.randint(0, 3)]\n",
    "        if activation == \"softmax\":\n",
    "            B = np.random.randint(low=1, high=20)\n",
    "            C = np.random.randint(low=1, high=20)\n",
    "            print(f\"Test {i+1}, B:{B}, C:{C}, activation: {activation}\")\n",
    "            x = np.random.randn(B, C)\n",
    "            y = layers.Activation(activation)\n",
    "            y_keras = y(x).numpy()\n",
    "            y_out = ActivationLayer(activation=activation).forward(x)\n",
    "            compare_tensors(\n",
    "                y_keras, y_out, tol=0.001, test_name=f\"Test Activation {i+1}\"\n",
    "            )\n",
    "        else:\n",
    "            B = np.random.randint(low=1, high=30)\n",
    "            C = np.random.randint(low=1, high=30)\n",
    "            H = np.random.randint(low=2, high=30)\n",
    "            W = np.random.randint(low=2, high=30)\n",
    "            print(f\"Test {i+1}, B:{B}, C:{C}, H:{H}, W:{W}, activation: {activation}\")\n",
    "            x = np.random.randn(B, C, H, W)\n",
    "            y = layers.Activation(activation)\n",
    "            y_keras = y(x).numpy()\n",
    "            y_out = ActivationLayer(activation=activation).forward(x)\n",
    "            compare_tensors(\n",
    "                y_keras, y_out, tol=0.001, test_name=f\"Test Activation {i+1}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3Bwcpw7X4_m",
    "outputId": "403fb796-93f6-433d-ee11-71ae74ae7bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Activation 1 Passed!\n",
      "Test Activation 2 Passed!\n",
      "Test Activation 3 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_ActivationLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUnCib0qlmWI",
    "outputId": "c01617d5-a508-469a-846e-3c9edea2dffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:5, C:29, H:4, W:17, activation: sigmoid\n",
      "Test Activation 1 Passed!\n",
      "Test 2, B:4, C:1, activation: softmax\n",
      "Test Activation 2 Passed!\n",
      "Test 3, B:24, C:22, H:27, W:20, activation: relu\n",
      "Test Activation 3 Passed!\n",
      "Test 4, B:17, C:16, activation: softmax\n",
      "Test Activation 4 Passed!\n",
      "Test 5, B:13, C:23, H:24, W:19, activation: sigmoid\n",
      "Test Activation 5 Passed!\n",
      "Test 6, B:8, C:16, activation: softmax\n",
      "Test Activation 6 Passed!\n",
      "Test 7, B:13, C:5, H:29, W:16, activation: sigmoid\n",
      "Test Activation 7 Passed!\n",
      "Test 8, B:10, C:28, H:6, W:16, activation: sigmoid\n",
      "Test Activation 8 Passed!\n",
      "Test 9, B:9, C:8, activation: softmax\n",
      "Test Activation 9 Passed!\n",
      "Test 10, B:26, C:4, H:4, W:4, activation: relu\n",
      "Test Activation 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_ActivationLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YtW9jiayUdV"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dOJl776Z0t7"
   },
   "source": [
    "* (3 балла) Реализация слоя пакетной нормализации **BatchNorm** (как для режима train, так и для режима test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0-bCGIE--8QH"
   },
   "outputs": [],
   "source": [
    "# Hint\n",
    "# Train mode:\n",
    "# out = (batch - mean(batch)) / sqrt(var(batch) + epsilon) * gamma + beta\n",
    "# moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\n",
    "# moving_var = moving_var * momentum + var(batch) * (1 - momentum)\n",
    "# Test mode:\n",
    "# (batch - moving_mean) / sqrt(moving_var + epsilon) * gamma + beta\n",
    "\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        momentum=0.99,\n",
    "        epsilon=0.001,\n",
    "        beta_init=None,\n",
    "        gamma_init=None,\n",
    "        moving_mean_init=None,\n",
    "        moving_var_init=None,\n",
    "        mode=\"train\",\n",
    "        input_channels=2,\n",
    "    ):\n",
    "        # mode: 'train', 'test'\n",
    "        # Параметры gamma, beta, mean, var - все имеют размерность по количеству карт input_channels\n",
    "        self.name = \"BatchNorm\"\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        self.beta = beta_init\n",
    "        self.gamma = gamma_init\n",
    "        self.moving_mean = moving_mean_init\n",
    "        self.moving_var = moving_var_init\n",
    "        self.mode = mode\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "        # 1) Нужно заполнить Numpy-тензор out (той же размерности, что и вход)\n",
    "        # 2) Нужно обновить moving_mean и moving_var в режиме 'train'\n",
    "        out = np.empty_like(input_data)\n",
    "        if self.mode == \"train\":\n",
    "            for i in range(self.input_channels):\n",
    "                mean = input_data[:, i, :, :].mean()\n",
    "                var = input_data[:, i, :, :].var()\n",
    "                out[:, i, :, :] = (input_data[:, i, :, :] - mean) / np.sqrt(\n",
    "                    var + self.epsilon\n",
    "                ) * self.gamma[i] + self.beta[i]\n",
    "                self.moving_mean[i] = self.moving_mean[i] * self.momentum + mean * (\n",
    "                    1 - self.momentum\n",
    "                )\n",
    "                self.moving_var[i] = self.moving_var[i] * self.momentum + var * (\n",
    "                    1 - self.momentum\n",
    "                )\n",
    "        elif self.mode == \"test\":\n",
    "            for i in range(self.input_channels):\n",
    "                out[:, i, :, :] = (\n",
    "                    (input_data[:, i, :, :] - self.moving_mean[i])\n",
    "                    / np.sqrt(self.moving_var[i] + self.epsilon)\n",
    "                    * self.gamma[i]\n",
    "                    + self.beta[i]\n",
    "                )\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NhZ6TK-RYfm-"
   },
   "outputs": [],
   "source": [
    "def test_BatchNormLayer():\n",
    "    B = 2\n",
    "    C = 2\n",
    "    H = 4\n",
    "    W = 4\n",
    "    beta_init = 0 * np.ones(C)\n",
    "    gamma_init = 1 * np.ones(C)\n",
    "    moving_mean_init = 0 * np.ones(C)\n",
    "    moving_var_init = 1 * np.ones(C)\n",
    "    momentum = 0.99\n",
    "    epsilon = 0.001\n",
    "    mode = \"train\"\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.BatchNormalization(\n",
    "        axis=1, momentum=momentum, epsilon=epsilon, trainable=True\n",
    "    )\n",
    "    y_keras = y(x, training=True).numpy()\n",
    "    y.set_weights([gamma_init, beta_init, moving_mean_init, moving_var_init])\n",
    "    y_keras = y(x, training=True).numpy()\n",
    "    y_out_layer = BatchNormLayer(\n",
    "        momentum=momentum,\n",
    "        epsilon=epsilon,\n",
    "        beta_init=beta_init,\n",
    "        gamma_init=gamma_init,\n",
    "        moving_mean_init=moving_mean_init,\n",
    "        moving_var_init=moving_var_init,\n",
    "        mode=mode,\n",
    "        input_channels=C,\n",
    "    )\n",
    "    y_out = y_out_layer.forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test BatchNorm 1\")\n",
    "    compare_tensors_array(\n",
    "        y.get_weights(),\n",
    "        [\n",
    "            y_out_layer.gamma,\n",
    "            y_out_layer.beta,\n",
    "            y_out_layer.moving_mean,\n",
    "            y_out_layer.moving_var,\n",
    "        ],\n",
    "        tol=0.00001,\n",
    "        test_name=\"Test BatchNorm 1.1\",\n",
    "    )\n",
    "    B = 2\n",
    "    C = 2\n",
    "    H = 4\n",
    "    W = 4\n",
    "    beta_init = 1 * np.ones(C)\n",
    "    gamma_init = 0 * np.ones(C)\n",
    "    moving_mean = 0 * np.ones(C)\n",
    "    moving_var = 1 * np.ones(C)\n",
    "    momentum = 0.99\n",
    "    epsilon = 0.001\n",
    "    mode = \"test\"\n",
    "    x = np.random.randn(B, C, H, W)\n",
    "    y = layers.BatchNormalization(\n",
    "        axis=1, momentum=momentum, epsilon=epsilon, trainable=False\n",
    "    )\n",
    "    y_keras = y(x, training=False).numpy()\n",
    "    y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\n",
    "    y_keras = y(x, training=False).numpy()\n",
    "    y_out_layer = BatchNormLayer(\n",
    "        momentum=momentum,\n",
    "        epsilon=epsilon,\n",
    "        beta_init=beta_init,\n",
    "        gamma_init=gamma_init,\n",
    "        moving_mean_init=moving_mean,\n",
    "        moving_var_init=moving_var,\n",
    "        mode=mode,\n",
    "        input_channels=C,\n",
    "    )\n",
    "    y_out = y_out_layer.forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test BatchNorm 2\")\n",
    "    compare_tensors_array(\n",
    "        y.get_weights(),\n",
    "        [\n",
    "            y_out_layer.gamma,\n",
    "            y_out_layer.beta,\n",
    "            y_out_layer.moving_mean,\n",
    "            y_out_layer.moving_var,\n",
    "        ],\n",
    "        tol=0.00001,\n",
    "        test_name=\"Test BatchNorm 2.1\",\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_BatchNormLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C = np.random.randint(low=1, high=30)\n",
    "        H = np.random.randint(low=2, high=30)\n",
    "        W = np.random.randint(low=2, high=30)\n",
    "        beta_init = 1 * np.ones(C)\n",
    "        gamma_init = 0 * np.ones(C)\n",
    "        moving_mean = 0 * np.ones(C)\n",
    "        moving_var = 1 * np.ones(C)\n",
    "        momentum = np.random.uniform(low=0.0, high=1.0)\n",
    "        print(f\"Test {i+1}, B:{B}, C:{C}, H:{H}, W:{W}, momentum: {momentum}\")\n",
    "        epsilon = 0.001\n",
    "        mode = \"test\"\n",
    "        x = np.random.randn(B, C, H, W)\n",
    "        y = layers.BatchNormalization(\n",
    "            axis=1, momentum=momentum, epsilon=epsilon, trainable=False\n",
    "        )\n",
    "        y_keras = y(x, training=False).numpy()\n",
    "        y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\n",
    "        y_keras = y(x, training=False).numpy()\n",
    "        y_out_layer = BatchNormLayer(\n",
    "            momentum=momentum,\n",
    "            epsilon=epsilon,\n",
    "            beta_init=beta_init,\n",
    "            gamma_init=gamma_init,\n",
    "            moving_mean_init=moving_mean,\n",
    "            moving_var_init=moving_var,\n",
    "            mode=mode,\n",
    "            input_channels=C,\n",
    "        )\n",
    "        y_out = y_out_layer.forward(x)\n",
    "        compare_tensors(y_keras, y_out, tol=0.001, test_name=f\"Test BatchNorm {i+1}\")\n",
    "        compare_tensors_array(\n",
    "            y.get_weights(),\n",
    "            [\n",
    "                y_out_layer.gamma,\n",
    "                y_out_layer.beta,\n",
    "                y_out_layer.moving_mean,\n",
    "                y_out_layer.moving_var,\n",
    "            ],\n",
    "            tol=0.00001,\n",
    "            test_name=f\"Test BatchNorm {i+1}.1\",\n",
    "        )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZ2F0Xg1Yf94",
    "outputId": "83263291-fbe8-4956-80f2-742c373b9d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BatchNorm 1 Passed!\n",
      "Test BatchNorm 1.1 subtest 0 Passed!\n",
      "Test BatchNorm 1.1 subtest 1 Passed!\n",
      "Test BatchNorm 1.1 subtest 2 Passed!\n",
      "Test BatchNorm 1.1 subtest 3 Passed!\n",
      "Test BatchNorm 1.1 Passed!\n",
      "Test BatchNorm 2 Passed!\n",
      "Test BatchNorm 2.1 subtest 0 Passed!\n",
      "Test BatchNorm 2.1 subtest 1 Passed!\n",
      "Test BatchNorm 2.1 subtest 2 Passed!\n",
      "Test BatchNorm 2.1 subtest 3 Passed!\n",
      "Test BatchNorm 2.1 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_BatchNormLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orhYgA94lmWJ",
    "outputId": "35a08474-b7ec-46fd-ab60-cf30203b60a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:20, C:2, H:29, W:27, momentum: 0.8504059464291097\n",
      "Test BatchNorm 1 Passed!\n",
      "Test BatchNorm 1.1 subtest 0 Passed!\n",
      "Test BatchNorm 1.1 subtest 1 Passed!\n",
      "Test BatchNorm 1.1 subtest 2 Passed!\n",
      "Test BatchNorm 1.1 subtest 3 Passed!\n",
      "Test BatchNorm 1.1 Passed!\n",
      "Test 2, B:20, C:24, H:27, W:6, momentum: 0.8108210855484291\n",
      "Test BatchNorm 2 Passed!\n",
      "Test BatchNorm 2.1 subtest 0 Passed!\n",
      "Test BatchNorm 2.1 subtest 1 Passed!\n",
      "Test BatchNorm 2.1 subtest 2 Passed!\n",
      "Test BatchNorm 2.1 subtest 3 Passed!\n",
      "Test BatchNorm 2.1 Passed!\n",
      "Test 3, B:3, C:27, H:6, W:22, momentum: 0.6747984657594498\n",
      "Test BatchNorm 3 Passed!\n",
      "Test BatchNorm 3.1 subtest 0 Passed!\n",
      "Test BatchNorm 3.1 subtest 1 Passed!\n",
      "Test BatchNorm 3.1 subtest 2 Passed!\n",
      "Test BatchNorm 3.1 subtest 3 Passed!\n",
      "Test BatchNorm 3.1 Passed!\n",
      "Test 4, B:26, C:15, H:23, W:16, momentum: 0.6616104852309141\n",
      "Test BatchNorm 4 Passed!\n",
      "Test BatchNorm 4.1 subtest 0 Passed!\n",
      "Test BatchNorm 4.1 subtest 1 Passed!\n",
      "Test BatchNorm 4.1 subtest 2 Passed!\n",
      "Test BatchNorm 4.1 subtest 3 Passed!\n",
      "Test BatchNorm 4.1 Passed!\n",
      "Test 5, B:20, C:25, H:7, W:12, momentum: 0.8264931043741401\n",
      "Test BatchNorm 5 Passed!\n",
      "Test BatchNorm 5.1 subtest 0 Passed!\n",
      "Test BatchNorm 5.1 subtest 1 Passed!\n",
      "Test BatchNorm 5.1 subtest 2 Passed!\n",
      "Test BatchNorm 5.1 subtest 3 Passed!\n",
      "Test BatchNorm 5.1 Passed!\n",
      "Test 6, B:10, C:29, H:5, W:4, momentum: 0.7884400767176246\n",
      "Test BatchNorm 6 Passed!\n",
      "Test BatchNorm 6.1 subtest 0 Passed!\n",
      "Test BatchNorm 6.1 subtest 1 Passed!\n",
      "Test BatchNorm 6.1 subtest 2 Passed!\n",
      "Test BatchNorm 6.1 subtest 3 Passed!\n",
      "Test BatchNorm 6.1 Passed!\n",
      "Test 7, B:21, C:22, H:23, W:21, momentum: 0.04334760565644169\n",
      "Test BatchNorm 7 Passed!\n",
      "Test BatchNorm 7.1 subtest 0 Passed!\n",
      "Test BatchNorm 7.1 subtest 1 Passed!\n",
      "Test BatchNorm 7.1 subtest 2 Passed!\n",
      "Test BatchNorm 7.1 subtest 3 Passed!\n",
      "Test BatchNorm 7.1 Passed!\n",
      "Test 8, B:5, C:14, H:21, W:25, momentum: 0.336610263646397\n",
      "Test BatchNorm 8 Passed!\n",
      "Test BatchNorm 8.1 subtest 0 Passed!\n",
      "Test BatchNorm 8.1 subtest 1 Passed!\n",
      "Test BatchNorm 8.1 subtest 2 Passed!\n",
      "Test BatchNorm 8.1 subtest 3 Passed!\n",
      "Test BatchNorm 8.1 Passed!\n",
      "Test 9, B:12, C:20, H:13, W:7, momentum: 0.10376033808123386\n",
      "Test BatchNorm 9 Passed!\n",
      "Test BatchNorm 9.1 subtest 0 Passed!\n",
      "Test BatchNorm 9.1 subtest 1 Passed!\n",
      "Test BatchNorm 9.1 subtest 2 Passed!\n",
      "Test BatchNorm 9.1 subtest 3 Passed!\n",
      "Test BatchNorm 9.1 Passed!\n",
      "Test 10, B:4, C:12, H:17, W:26, momentum: 0.25745699069438954\n",
      "Test BatchNorm 10 Passed!\n",
      "Test BatchNorm 10.1 subtest 0 Passed!\n",
      "Test BatchNorm 10.1 subtest 1 Passed!\n",
      "Test BatchNorm 10.1 subtest 2 Passed!\n",
      "Test BatchNorm 10.1 subtest 3 Passed!\n",
      "Test BatchNorm 10.1 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_BatchNormLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJKt_4mCyV4r"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f_m9DaTaHio"
   },
   "source": [
    "* (1 балл) Реализация **полносвязного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1Ln22ERp8mC5"
   },
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
    "        self.name = \"Dense\"\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = W_init\n",
    "        self.b = b_init\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # На входе - двухмерный тензор вида [batch, input_channels]\n",
    "        # Работаем по второй размерности, по первой размерности НЕ преобразуем\n",
    "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "        # Нужно заполнить Numpy-тензор out\n",
    "        assert input_data.shape[1] == self.W.shape[0], \"Mismatch in dimensions\"\n",
    "        out = input_data @ self.W + self.b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ln9JIKL8YhZF"
   },
   "outputs": [],
   "source": [
    "def test_DenseLayer():\n",
    "    B = 1\n",
    "    C_IN = 10\n",
    "    C_OUT = 5\n",
    "    x = np.random.randn(B, C_IN)\n",
    "    W_init = np.random.randn(C_IN, C_OUT)\n",
    "    b_init = np.random.randn(C_OUT)\n",
    "    y = layers.Dense(C_OUT, use_bias=True)\n",
    "    y_keras = y(x).numpy()\n",
    "    y.set_weights([W_init, b_init])\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Dense 1\")\n",
    "    B = 2\n",
    "    C_IN = 5\n",
    "    C_OUT = 10\n",
    "    x = np.random.randn(B, C_IN)\n",
    "    W_init = np.random.randn(C_IN, C_OUT)\n",
    "    b_init = np.random.randn(C_OUT)\n",
    "    y = layers.Dense(C_OUT, use_bias=True, input_shape=(C_IN,))\n",
    "    y_keras = y(x).numpy()\n",
    "    y.set_weights([W_init, b_init])\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Dense 2\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_DenseLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C_IN = np.random.randint(low=1, high=30)\n",
    "        C_OUT = np.random.randint(low=1, high=30)\n",
    "        print(f\"Test {i+1}, B:{B}, C_IN:{C_IN}, C_OUT:{C_OUT}\")\n",
    "        x = np.random.randn(B, C_IN)\n",
    "        W_init = np.random.randn(C_IN, C_OUT)\n",
    "        b_init = np.random.randn(C_OUT)\n",
    "        y = layers.Dense(C_OUT, use_bias=True)\n",
    "        y_keras = y(x).numpy()\n",
    "        y.set_weights([W_init, b_init])\n",
    "        y_keras = y(x).numpy()\n",
    "        y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "        compare_tensors(y_keras, y_out, tol=0.001, test_name=f\"Test Dense {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NA_KNjZYhec",
    "outputId": "d7bc8f2c-e3ed-4ad7-9dde-fa9fad3ec27e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dense 1 Passed!\n",
      "Test Dense 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_DenseLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2BPi8dDlmWK",
    "outputId": "4f35025b-2d20-4ca6-d6cf-00bffb5b6977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:20, C_IN:14, C_OUT:9\n",
      "Test Dense 1 Passed!\n",
      "Test 2, B:19, C_IN:4, C_OUT:14\n",
      "Test Dense 2 Passed!\n",
      "Test 3, B:15, C_IN:2, C_OUT:1\n",
      "Test Dense 3 Passed!\n",
      "Test 4, B:9, C_IN:24, C_OUT:22\n",
      "Test Dense 4 Passed!\n",
      "Test 5, B:23, C_IN:16, C_OUT:25\n",
      "Test Dense 5 Passed!\n",
      "Test 6, B:28, C_IN:25, C_OUT:9\n",
      "Test Dense 6 Passed!\n",
      "Test 7, B:16, C_IN:25, C_OUT:25\n",
      "Test Dense 7 Passed!\n",
      "Test 8, B:28, C_IN:16, C_OUT:23\n",
      "Test Dense 8 Passed!\n",
      "Test 9, B:20, C_IN:20, C_OUT:19\n",
      "Test Dense 9 Passed!\n",
      "Test 10, B:12, C_IN:11, C_OUT:26\n",
      "Test Dense 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_DenseLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "966wyQwryXun"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6A8OLysaS3Q"
   },
   "source": [
    "* (2 балла) Реализация **сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "quhEATTW9jyK"
   },
   "outputs": [],
   "source": [
    "class Conv2DLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size=3,\n",
    "        input_channels=2,\n",
    "        output_channels=3,\n",
    "        padding=\"same\",\n",
    "        stride=1,\n",
    "        K_init=None,\n",
    "        b_init=None,\n",
    "    ):\n",
    "        # padding: 'same' или 'valid'\n",
    "        # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "        # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
    "        # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "        self.name = \"Conv2D\"\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel = K_init\n",
    "        self.bias = b_init\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        if self.padding == \"same\":\n",
    "            if input_data.shape[2] % self.stride == 0:\n",
    "                pad_h = max(self.kernel_size - self.stride, 0)\n",
    "            else:\n",
    "                pad_h = max(self.kernel_size - (input_data.shape[2] % self.stride), 0)\n",
    "            if input_data.shape[3] % self.stride == 0:\n",
    "                pad_w = max(self.kernel_size - self.stride, 0)\n",
    "            else:\n",
    "                pad_w = max(self.kernel_size - (input_data.shape[3] % self.stride), 0)\n",
    "            pad_top = pad_h // 2\n",
    "            pad_bottom = pad_h - pad_top\n",
    "            pad_left = pad_w // 2\n",
    "            pad_right = pad_w - pad_left\n",
    "            temp_input_data = np.pad(\n",
    "                input_data,\n",
    "                ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n",
    "            )\n",
    "            temp_input_data[\n",
    "                :,\n",
    "                :,\n",
    "                pad_top : pad_top + input_data.shape[2],\n",
    "                pad_left : pad_left + input_data.shape[3],\n",
    "            ] = input_data\n",
    "        else:\n",
    "            temp_input_data = input_data\n",
    "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "        # Нужно заполнить Numpy-тензор out\n",
    "\n",
    "        out_h = (\n",
    "            temp_input_data.shape[2] - self.kernel_size + self.stride\n",
    "        ) // self.stride\n",
    "        out_w = (\n",
    "            temp_input_data.shape[3] - self.kernel_size + self.stride\n",
    "        ) // self.stride\n",
    "        out = np.zeros((input_data.shape[0], self.output_channels, out_h, out_w))\n",
    "        for oc in range(self.output_channels):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    out[:, oc, i, j] = (\n",
    "                        np.tensordot(\n",
    "                            temp_input_data[\n",
    "                                :,\n",
    "                                :,\n",
    "                                i * self.stride : i * self.stride + self.kernel_size,\n",
    "                                j * self.stride : j * self.stride + self.kernel_size,\n",
    "                            ],\n",
    "                            self.kernel[:, :, :, oc],\n",
    "                            axes=([2, 3, 1], [0, 1, 2]),\n",
    "                        )\n",
    "                        + self.bias[oc]\n",
    "                    )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "aUA1PbOBYiH3"
   },
   "outputs": [],
   "source": [
    "def test_Conv2DLayer():\n",
    "    B = 1\n",
    "    C_IN = 1\n",
    "    C_OUT = 1\n",
    "    H = 10\n",
    "    W = 10\n",
    "    K = 3\n",
    "    S = 1\n",
    "    padding = \"same\"\n",
    "    x = np.random.randn(B, C_IN, H, W)\n",
    "    K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "    b_init = np.random.randn(C_OUT)\n",
    "    y = layers.Conv2D(\n",
    "        C_OUT,\n",
    "        K,\n",
    "        strides=S,\n",
    "        padding=padding,\n",
    "        data_format=\"channels_first\",\n",
    "        dilation_rate=1,\n",
    "        groups=1,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "    )\n",
    "    y_keras = y(x).numpy()\n",
    "    y.set_weights([K_init, b_init])\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = Conv2DLayer(\n",
    "        kernel_size=K,\n",
    "        input_channels=C_IN,\n",
    "        output_channels=C_OUT,\n",
    "        padding=padding,\n",
    "        stride=S,\n",
    "        K_init=K_init,\n",
    "        b_init=b_init,\n",
    "    ).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Conv2D 1\")\n",
    "    B = 2\n",
    "    C_IN = 3\n",
    "    C_OUT = 5\n",
    "    H = 9\n",
    "    W = 9\n",
    "    K = 3\n",
    "    S = 2\n",
    "    padding = \"valid\"\n",
    "    x = np.random.randn(B, C_IN, H, W)\n",
    "    K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "    b_init = np.random.randn(C_OUT)\n",
    "    y = layers.Conv2D(\n",
    "        C_OUT,\n",
    "        K,\n",
    "        strides=S,\n",
    "        padding=padding,\n",
    "        data_format=\"channels_first\",\n",
    "        dilation_rate=1,\n",
    "        groups=1,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        input_shape=(H, W, C_IN),\n",
    "    )\n",
    "    y_keras = y(x).numpy()\n",
    "    y.set_weights([K_init, b_init])\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = Conv2DLayer(\n",
    "        kernel_size=K,\n",
    "        input_channels=C_IN,\n",
    "        output_channels=C_OUT,\n",
    "        padding=padding,\n",
    "        stride=S,\n",
    "        K_init=K_init,\n",
    "        b_init=b_init,\n",
    "    ).forward(x)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Conv2D 2\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_Conv2DLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        paddings = [\"same\", \"valid\"]\n",
    "        padding = paddings[np.random.randint(low=0, high=2)]\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C_IN = np.random.randint(low=1, high=30)\n",
    "        C_OUT = np.random.randint(low=1, high=30)\n",
    "        H = np.random.randint(low=2, high=30)\n",
    "        W = np.random.randint(low=2, high=30)\n",
    "        K = np.random.randint(\n",
    "            low=1, high=30 if padding == \"same\" else max(2, min(H, W))\n",
    "        )\n",
    "        S = np.random.randint(\n",
    "            low=1, high=30 if padding == \"same\" else max(2, min(H, W))\n",
    "        )\n",
    "        print(\n",
    "            f\"Test {i+1}, B:{B}, C_IN:{C_IN}, C_OUT:{C_OUT}, H:{H}, W:{W}, K:{K}, S:{S}, Padding:{padding}\"\n",
    "        )\n",
    "        x = np.random.randn(B, C_IN, H, W)\n",
    "        K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "        b_init = np.random.randn(C_OUT)\n",
    "        y = layers.Conv2D(\n",
    "            C_OUT,\n",
    "            K,\n",
    "            strides=S,\n",
    "            padding=padding,\n",
    "            data_format=\"channels_first\",\n",
    "            dilation_rate=1,\n",
    "            groups=1,\n",
    "            activation=None,\n",
    "            use_bias=True,\n",
    "        )\n",
    "        y_keras = y(x).numpy()\n",
    "        y.set_weights([K_init, b_init])\n",
    "        y_keras = y(x).numpy()\n",
    "        y_out = Conv2DLayer(\n",
    "            kernel_size=K,\n",
    "            input_channels=C_IN,\n",
    "            output_channels=C_OUT,\n",
    "            padding=padding,\n",
    "            stride=S,\n",
    "            K_init=K_init,\n",
    "            b_init=b_init,\n",
    "        ).forward(x)\n",
    "        compare_tensors(\n",
    "            y_keras, y_out, tol=0.001, test_name=f\"Random test Conv2D {i+1}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VSRtCfDlmWL",
    "outputId": "212ad798-e076-44ea-f6a0-9bd1e9413460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:21, C_IN:28, C_OUT:5, H:16, W:28, K:15, S:2, Padding:valid\n",
      "Random test Conv2D 1 Passed!\n",
      "Test 2, B:13, C_IN:2, C_OUT:3, H:26, W:27, K:12, S:19, Padding:valid\n",
      "Random test Conv2D 2 Passed!\n",
      "Test 3, B:26, C_IN:5, C_OUT:29, H:26, W:24, K:29, S:26, Padding:same\n",
      "Random test Conv2D 3 Passed!\n",
      "Test 4, B:8, C_IN:15, C_OUT:14, H:29, W:2, K:1, S:1, Padding:valid\n",
      "Random test Conv2D 4 Passed!\n",
      "Test 5, B:10, C_IN:4, C_OUT:4, H:14, W:3, K:2, S:1, Padding:valid\n",
      "Random test Conv2D 5 Passed!\n",
      "Test 6, B:26, C_IN:27, C_OUT:16, H:11, W:19, K:4, S:10, Padding:valid\n",
      "Random test Conv2D 6 Passed!\n",
      "Test 7, B:17, C_IN:18, C_OUT:21, H:7, W:19, K:2, S:1, Padding:valid\n",
      "Random test Conv2D 7 Passed!\n",
      "Test 8, B:23, C_IN:5, C_OUT:13, H:10, W:17, K:1, S:1, Padding:valid\n",
      "Random test Conv2D 8 Passed!\n",
      "Test 9, B:9, C_IN:15, C_OUT:20, H:14, W:7, K:29, S:27, Padding:same\n",
      "Random test Conv2D 9 Passed!\n",
      "Test 10, B:26, C_IN:26, C_OUT:11, H:23, W:13, K:2, S:9, Padding:valid\n",
      "Random test Conv2D 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_Conv2DLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZI5iUu4YiOD",
    "outputId": "3ea7e51f-00e5-499b-cb0b-fe1ef09de6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Conv2D 1 Passed!\n",
      "Test Conv2D 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_Conv2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91-bDvSvyY2e"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hPqOr5zad6H"
   },
   "source": [
    "* (2 балла) Реализация **транспонированного сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "97D7QOwm-ER1"
   },
   "outputs": [],
   "source": [
    "class Conv2DTrLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size=3,\n",
    "        input_channels=2,\n",
    "        output_channels=3,\n",
    "        padding=\"valid\",\n",
    "        stride=1,\n",
    "        K_init=None,\n",
    "        b_init=None,\n",
    "    ):\n",
    "        # padding: число (сколько отрезать от модифицированной входной карты)\n",
    "        # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "        # stride - одно число (коэффициент расширения)\n",
    "        # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "        self.name = \"Conv2DTr\"\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel = K_init\n",
    "        self.bias = b_init\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "        # Нужно заполнить Numpy-тензор out\n",
    "\n",
    "        out_h = (input_data.shape[2] - 1) * self.stride + self.kernel_size\n",
    "        out_w = (input_data.shape[3] - 1) * self.stride + self.kernel_size\n",
    "        out = np.zeros((input_data.shape[0], self.output_channels, out_h, out_w))\n",
    "        for oc in range(self.output_channels):\n",
    "            for i in range(input_data.shape[2]):\n",
    "                for j in range(input_data.shape[3]):\n",
    "                    for k1 in range(self.kernel_size):\n",
    "                        for k2 in range(self.kernel_size):\n",
    "                            out[\n",
    "                                :, oc, i * self.stride + k1, j * self.stride + k2\n",
    "                            ] += np.sum(\n",
    "                                self.kernel[k1, k2, oc, :] * input_data[:, :, i, j],\n",
    "                                axis=1,\n",
    "                            )\n",
    "            out[:, oc] += self.bias[oc]\n",
    "\n",
    "        p_left_top, p_right_bot = 0, 0\n",
    "        if self.padding == \"same\":\n",
    "            p_left_top = (self.kernel_size - self.stride) // 2\n",
    "            p_right_bot = self.kernel_size - self.stride - p_left_top\n",
    "\n",
    "        return out[\n",
    "            :,\n",
    "            :,\n",
    "            p_left_top : out.shape[2] - p_right_bot,\n",
    "            p_left_top : out.shape[3] - p_right_bot,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ueU3lS9-Yi8t"
   },
   "outputs": [],
   "source": [
    "def adjust_kernel(K):\n",
    "    K_new = K.copy()[::-1, ::-1, :, :]\n",
    "    K_new = np.transpose(K_new, (0, 1, 3, 2))\n",
    "    return K_new\n",
    "\n",
    "\n",
    "def test_Conv2DTrLayer():\n",
    "    B = 1\n",
    "    C_IN = 1\n",
    "    C_OUT = 1\n",
    "    H = 3\n",
    "    W = 3\n",
    "    K = 3\n",
    "    S = 2\n",
    "    padding = 0\n",
    "    x = np.random.randn(B, C_IN, H, W)\n",
    "    K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "    b_init = np.random.randn(C_OUT)\n",
    "    y = layers.Conv2DTranspose(\n",
    "        C_OUT,\n",
    "        K,\n",
    "        strides=S,\n",
    "        padding=\"valid\",\n",
    "        output_padding=None,\n",
    "        data_format=\"channels_first\",\n",
    "        dilation_rate=1,\n",
    "        groups=1,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "    )\n",
    "    y_keras = y(x).numpy()\n",
    "    y.set_weights([adjust_kernel(K_init), b_init])\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = Conv2DTrLayer(\n",
    "        kernel_size=K,\n",
    "        input_channels=C_IN,\n",
    "        output_channels=C_OUT,\n",
    "        padding=\"valid\",\n",
    "        stride=S,\n",
    "        K_init=adjust_kernel(K_init),\n",
    "        b_init=b_init,\n",
    "    ).forward(x)\n",
    "    np.set_printoptions(precision=1)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Conv2DTr 1\")\n",
    "\n",
    "    B = 4\n",
    "    C_IN = 2\n",
    "    C_OUT = 3\n",
    "    H = 3\n",
    "    W = 3\n",
    "    K = 3\n",
    "    S = 2\n",
    "    padding = \"valid\"\n",
    "    x = np.random.randn(B, C_IN, H, W)\n",
    "    K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "    b_init = np.random.randn(C_OUT)\n",
    "    y = layers.Conv2DTranspose(\n",
    "        C_OUT,\n",
    "        K,\n",
    "        strides=S,\n",
    "        padding=\"valid\",\n",
    "        output_padding=None,\n",
    "        data_format=\"channels_first\",\n",
    "        dilation_rate=1,\n",
    "        groups=1,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "    )\n",
    "    y_keras = y(x).numpy()\n",
    "    y.set_weights([adjust_kernel(K_init), b_init])\n",
    "    y_keras = y(x).numpy()\n",
    "    y_out = Conv2DTrLayer(\n",
    "        kernel_size=K,\n",
    "        input_channels=C_IN,\n",
    "        output_channels=C_OUT,\n",
    "        padding=\"valid\",\n",
    "        stride=S,\n",
    "        K_init=adjust_kernel(K_init),\n",
    "        b_init=b_init,\n",
    "    ).forward(x)\n",
    "    np.set_printoptions(precision=1)\n",
    "    compare_tensors(y_keras, y_out, tol=0.001, test_name=\"Test Conv2DTr 2\")\n",
    "    return\n",
    "\n",
    "\n",
    "def random_test_Conv2DTrLayer(num_tests=10):\n",
    "    for i in range(num_tests):\n",
    "        paddings = [\"same\", \"valid\"]\n",
    "        padding = paddings[np.random.randint(low=0, high=2)]\n",
    "        B = np.random.randint(low=1, high=30)\n",
    "        C_IN = np.random.randint(low=1, high=30)\n",
    "        C_OUT = np.random.randint(low=1, high=30)\n",
    "        H = np.random.randint(low=2, high=30)\n",
    "        W = np.random.randint(low=2, high=30)\n",
    "        K = np.random.randint(low=1, high=30)\n",
    "        S = np.random.randint(low=1, high=max(2, K))\n",
    "        print(\n",
    "            f\"Test {i+1}, B:{B}, C_IN:{C_IN}, C_OUT:{C_OUT}, H:{H}, W:{W}, K:{K}, S:{S}, Padding:{padding}\"\n",
    "        )\n",
    "        x = np.random.randn(B, C_IN, H, W)\n",
    "        K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "        b_init = np.random.randn(C_OUT)\n",
    "        y = layers.Conv2DTranspose(\n",
    "            C_OUT,\n",
    "            K,\n",
    "            strides=S,\n",
    "            padding=padding,\n",
    "            output_padding=None,\n",
    "            data_format=\"channels_first\",\n",
    "            dilation_rate=1,\n",
    "            groups=1,\n",
    "            activation=None,\n",
    "            use_bias=True,\n",
    "        )\n",
    "        y_keras = y(x).numpy()\n",
    "        y.set_weights([adjust_kernel(K_init), b_init])\n",
    "        y_keras = y(x).numpy()\n",
    "        y_out = Conv2DTrLayer(\n",
    "            kernel_size=K,\n",
    "            input_channels=C_IN,\n",
    "            output_channels=C_OUT,\n",
    "            padding=padding,\n",
    "            stride=S,\n",
    "            K_init=adjust_kernel(K_init),\n",
    "            b_init=b_init,\n",
    "        ).forward(x)\n",
    "        np.set_printoptions(precision=1)\n",
    "        compare_tensors(y_keras, y_out, tol=0.001, test_name=f\"Test Conv2DTr {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rW2REQR3-6dd",
    "outputId": "382bb342-6bb6-46f8-fbaf-d024273b63fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Conv2DTr 1 Passed!\n",
      "Test Conv2DTr 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_Conv2DTrLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsFyVopAc6Vl",
    "outputId": "2d3af17e-851f-4eaf-d586-f9f1ff4f5acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1, B:16, C_IN:2, C_OUT:1, H:19, W:28, K:25, S:7, Padding:valid\n",
      "Test Conv2DTr 1 Passed!\n",
      "Test 2, B:26, C_IN:17, C_OUT:6, H:6, W:19, K:12, S:7, Padding:valid\n",
      "Test Conv2DTr 2 Passed!\n",
      "Test 3, B:21, C_IN:5, C_OUT:7, H:18, W:26, K:15, S:12, Padding:valid\n",
      "Test Conv2DTr 3 Passed!\n",
      "Test 4, B:15, C_IN:26, C_OUT:24, H:4, W:8, K:13, S:2, Padding:same\n",
      "Test Conv2DTr 4 Passed!\n",
      "Test 5, B:9, C_IN:12, C_OUT:3, H:28, W:4, K:20, S:7, Padding:valid\n",
      "Test Conv2DTr 5 Passed!\n",
      "Test 6, B:18, C_IN:5, C_OUT:6, H:7, W:7, K:12, S:8, Padding:same\n",
      "Test Conv2DTr 6 Passed!\n",
      "Test 7, B:28, C_IN:8, C_OUT:11, H:5, W:28, K:9, S:2, Padding:same\n",
      "Test Conv2DTr 7 Passed!\n",
      "Test 8, B:8, C_IN:27, C_OUT:8, H:9, W:11, K:18, S:1, Padding:same\n",
      "Test Conv2DTr 8 Passed!\n",
      "Test 9, B:17, C_IN:12, C_OUT:15, H:24, W:14, K:3, S:2, Padding:same\n",
      "Test Conv2DTr 9 Passed!\n",
      "Test 10, B:12, C_IN:22, C_OUT:13, H:9, W:2, K:26, S:15, Padding:same\n",
      "Test Conv2DTr 10 Passed!\n"
     ]
    }
   ],
   "source": [
    "random_test_Conv2DTrLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PlmWncfijH-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Practice01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
